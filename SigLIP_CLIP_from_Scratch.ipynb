{
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1413358,
          "sourceType": "datasetVersion",
          "datasetId": 823708
        },
        {
          "sourceId": 7558580,
          "sourceType": "datasetVersion",
          "datasetId": 4401550
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "SigLIP / CLIP from Scratch",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'random-image-for-testing-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F823708%2F1413358%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240811%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240811T232501Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D778aca31c9d2d45b1d7a035fa239af647f68021731df4636ce729bd34fb487fde940363f7e22f3a432acdbdaf26db1ad1b9e76e1b11bb078cdeb13c3366d0e92349644553c3fcfc22056613faf6fabe31578e3e9715784989a5c267098ea12de9894ae62cff6017365fe503c50e15531c8d1a9e45b7de9f06e2a1e5c1d97b058f814bbf888a77354a80c17e679664ce4c314e2c00399fa004f00a73b9d2d3b99add322599284a265afc3dbb1aab016cb6c82a0434ab6c98ed12f0f8d4add417de2a1fbb38fc43daa1bc2b5fc5d357bc958d5ba585d1b5d90f40c99e01ef1690dc64203d949cfa1c3b610b1eca3cb1f4e002acb521b57897c14de037b7600eb5c,flickr30k-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4401550%2F7558580%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240811%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240811T232501Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D532be343a3760455e93cab4c13a61a3971c78c39e940a4db282e30b3748f6251a5cea848afb593810a55895dd9725ed8d014b99dc48cf27c85551d4522fb2400b8f0e5a8e1993146d0120cd40048e903021707f30e86d829bac4b7a68dc0ca3e282151d42d2b394729530ce65c80df977318a08498f44374b46aa9145b3b8d6ee62fa4a5e5788857758b1a0978347fedb96b9ed1c9b3999c2a3fd0c1dc3c60448b925de35f60772b43e3c3aa6666dff49f184cdba8a1ef56713e11c01256e61d557fb8468e280138b3fed2b8cc056322b22da2ccae6cac4e4a80506db71bab4f5aec38c9332e6d3df1da4cc63f51179480b9eb5ad634b9fa5eab2e1c384cfd27'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "juau3vDwwndI"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ† | Install Libraries"
      ],
      "metadata": {
        "id": "dUiYTiHIwndL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning timm torchinfo wandb"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "L_OM9kZlwndM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 55d0dbf56bdd3224ddc3a254f8cdea33f62cdb72"
      ],
      "metadata": {
        "trusted": true,
        "id": "vSka4JiUwndM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö | Import Libraries"
      ],
      "metadata": {
        "id": "DQHt3QxGwndM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import timm\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "import torch, torch.nn as nn,torch.nn.functional as F\n",
        "from lightning.pytorch import seed_everything\n",
        "from lightning import LightningDataModule\n",
        "from lightning import Trainer\n",
        "from lightning import LightningModule\n",
        "import lightning.pytorch as pl\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import AutoTokenizer, AutoModel, DistilBertForSequenceClassification, DistilBertModel, DistilBertTokenizer\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from torchinfo import summary\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:22.692032Z",
          "iopub.execute_input": "2024-03-22T20:57:22.692319Z",
          "iopub.status.idle": "2024-03-22T20:57:30.130014Z",
          "shell.execute_reply.started": "2024-03-22T20:57:22.692277Z",
          "shell.execute_reply": "2024-03-22T20:57:30.12917Z"
        },
        "trusted": true,
        "id": "i4MpgIbCwndN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öôÔ∏è | Configuration"
      ],
      "metadata": {
        "id": "E6kbvRx5wndN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    debug = False\n",
        "    seed = 42\n",
        "    image_preset = \"tiny_vit_21m_224.dist_in22k_ft_in1k\"\n",
        "    image_size = [224, 224]\n",
        "    image_path = \"/kaggle/input/flickr30k-dataset/Images\"\n",
        "    caption_path = \"/kaggle/input/flickr30k-dataset\"\n",
        "    text_preset = \"SmartComponents/bge-micro-v2\"\n",
        "    sequence_length = 200\n",
        "    batch_size = 64\n",
        "    device = 'cuda:0'\n",
        "    epochs = 8\n",
        "    embedding_dim = 256\n",
        "\n",
        "    dropout = 0.1\n",
        "    lr = 3e-4\n",
        "    T_max = 3\n",
        "    eta_min = 1e-6\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(CFG.device)\n",
        "seed_everything(CFG.seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:30.135045Z",
          "iopub.execute_input": "2024-03-22T20:57:30.135381Z",
          "iopub.status.idle": "2024-03-22T20:57:30.146705Z",
          "shell.execute_reply.started": "2024-03-22T20:57:30.135354Z",
          "shell.execute_reply": "2024-03-22T20:57:30.145741Z"
        },
        "trusted": true,
        "id": "sC-dTxvVwndN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ôªÔ∏è | Reproducibility"
      ],
      "metadata": {
        "id": "2XWPIUuGwndN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ | Meta Data"
      ],
      "metadata": {
        "id": "bldrGwjWwndO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(f\"{CFG.caption_path}/captions.txt\")\n",
        "df[\"image_path\"] = CFG.image_path + \"/\" + df.image\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:30.147759Z",
          "iopub.execute_input": "2024-03-22T20:57:30.148478Z",
          "iopub.status.idle": "2024-03-22T20:57:30.421758Z",
          "shell.execute_reply.started": "2024-03-22T20:57:30.148445Z",
          "shell.execute_reply": "2024-03-22T20:57:30.420761Z"
        },
        "trusted": true,
        "id": "W1jsBH5BwndO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if CFG.debug:\n",
        "    df = df.iloc[:5000]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:30.424187Z",
          "iopub.execute_input": "2024-03-22T20:57:30.424523Z",
          "iopub.status.idle": "2024-03-22T20:57:30.428648Z",
          "shell.execute_reply.started": "2024-03-22T20:57:30.424495Z",
          "shell.execute_reply": "2024-03-22T20:57:30.427807Z"
        },
        "trusted": true,
        "id": "1h4uC86zwndO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df = df.dropna(subset=['caption'])\n",
        "df['caption'] = df['caption'].str.strip()\n",
        "df = df.reset_index(drop=True)\n",
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:30.42984Z",
          "iopub.execute_input": "2024-03-22T20:57:30.430112Z",
          "iopub.status.idle": "2024-03-22T20:57:30.558657Z",
          "shell.execute_reply.started": "2024-03-22T20:57:30.43009Z",
          "shell.execute_reply": "2024-03-22T20:57:30.55776Z"
        },
        "trusted": true,
        "id": "GGjg9w2wwndO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=CFG.seed)\n",
        "\n",
        "df['fold'] = -1\n",
        "\n",
        "for fold, (_, valid_index) in enumerate(skf.split(X=df, y=df['image_path'])):\n",
        "    df.loc[valid_index, 'fold'] = fold\n",
        "\n",
        "\n",
        "train_df = df[df['fold'] != 0].reset_index(drop=True)\n",
        "valid_df = df[df['fold'] == 0].reset_index(drop=True)\n",
        "print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n",
        "\n",
        "train_paths = train_df.image_path.values\n",
        "train_texts = train_df.caption.values\n",
        "valid_paths = valid_df.image_path.values\n",
        "\n",
        "valid_texts = valid_df.caption.values\n",
        "\n",
        "'''\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "df['fold'] = -1\n",
        "for fold, (train_index, valid_index) in enumerate(gkf.split(df, groups=df[\"image\"])):\n",
        "    df.loc[valid_index, 'fold'] = fold\n",
        "sample_df = df.groupby(\"image\").head(1).reset_index(drop=True)\n",
        "train_df = sample_df[sample_df.fold != 0]\n",
        "valid_df = sample_df[sample_df.fold == 0]\n",
        "print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n",
        "\n",
        "train_paths = train_df.image_path.values\n",
        "train_texts = train_df.caption.values\n",
        "valid_paths = valid_df.image_path.values\n",
        "\n",
        "valid_texts = valid_df.caption.values'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:30.559977Z",
          "iopub.execute_input": "2024-03-22T20:57:30.560244Z",
          "iopub.status.idle": "2024-03-22T20:57:33.95983Z",
          "shell.execute_reply.started": "2024-03-22T20:57:30.560221Z",
          "shell.execute_reply": "2024-03-22T20:57:33.958912Z"
        },
        "trusted": true,
        "id": "pTtl7y0uwndO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî™ | Data Split"
      ],
      "metadata": {
        "id": "rPoQhsE2wndO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçö | DataLoader"
      ],
      "metadata": {
        "id": "UnNbrk3gwndP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageTextDataset(Dataset):\n",
        "    def __init__(self, image_filenames, captions, transforms, image_size=CFG.image_size[0]):\n",
        "        self.image_filenames = image_filenames\n",
        "        self.captions = captions\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(self.image_filenames[index])\n",
        "        image = self.transforms(image)\n",
        "        text = self.captions[index]\n",
        "\n",
        "        return image, text\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:33.961183Z",
          "iopub.execute_input": "2024-03-22T20:57:33.961862Z",
          "iopub.status.idle": "2024-03-22T20:57:33.96774Z",
          "shell.execute_reply.started": "2024-03-22T20:57:33.961836Z",
          "shell.execute_reply": "2024-03-22T20:57:33.966763Z"
        },
        "trusted": true,
        "id": "V-oEMZzMwndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageTextDataModule(LightningDataModule):\n",
        "    def __init__(self, train_paths, train_texts, valid_paths, valid_texts, batch_size=CFG.batch_size, image_size=CFG.image_size):\n",
        "        super().__init__()\n",
        "        self.train_paths = train_paths\n",
        "        self.train_texts = train_texts\n",
        "        self.valid_paths = valid_paths\n",
        "        self.valid_texts = valid_texts\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((self.image_size[0], self.image_size[0])),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = ImageTextDataset(self.train_paths, self.train_texts, self.transform)\n",
        "        self.valid_dataset = ImageTextDataset(self.valid_paths, self.valid_texts, self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.valid_dataset, batch_size=self.batch_size, shuffle=False, drop_last=True, num_workers=4, pin_memory=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:33.969061Z",
          "iopub.execute_input": "2024-03-22T20:57:33.969609Z",
          "iopub.status.idle": "2024-03-22T20:57:33.981815Z",
          "shell.execute_reply.started": "2024-03-22T20:57:33.969577Z",
          "shell.execute_reply": "2024-03-22T20:57:33.980972Z"
        },
        "trusted": true,
        "id": "ZYlIXY-QwndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîç | Loss"
      ],
      "metadata": {
        "id": "1_oeQhaEwndP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ | Modeling"
      ],
      "metadata": {
        "id": "KjSejkmGwndP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projection Head"
      ],
      "metadata": {
        "id": "Ort_fbE1wndP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim, embedding_dim=CFG.embedding_dim, dropout=CFG.dropout):\n",
        "        super(ProjectionHead, self).__init__()\n",
        "        self.projection = nn.Linear(in_dim, embedding_dim)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.fc = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        projected = self.projection(x)\n",
        "        x = self.gelu(projected)\n",
        "        x = self.fc(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + projected\n",
        "        x = self.layer_norm(x)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:33.982927Z",
          "iopub.execute_input": "2024-03-22T20:57:33.983231Z",
          "iopub.status.idle": "2024-03-22T20:57:33.99146Z",
          "shell.execute_reply.started": "2024-03-22T20:57:33.983208Z",
          "shell.execute_reply": "2024-03-22T20:57:33.990745Z"
        },
        "trusted": true,
        "id": "1ExN-bncwndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Encoder"
      ],
      "metadata": {
        "id": "9LDphIZSwndP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedConvNeXt(nn.Module):\n",
        "    def __init__(self, backbone_name, pretrained=True):\n",
        "        super(ModifiedConvNeXt, self).__init__()\n",
        "        backbone = timm.create_model(backbone_name, pretrained=pretrained)\n",
        "        backbone.head.fc = nn.Identity()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = ProjectionHead(576)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.projection_head(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def build_image_encoder(model_name=CFG.image_preset):\n",
        "    model = ModifiedConvNeXt(backbone_name=model_name, pretrained=True)\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:33.992391Z",
          "iopub.execute_input": "2024-03-22T20:57:33.992625Z",
          "iopub.status.idle": "2024-03-22T20:57:34.006136Z",
          "shell.execute_reply.started": "2024-03-22T20:57:33.992604Z",
          "shell.execute_reply": "2024-03-22T20:57:34.005421Z"
        },
        "trusted": true,
        "id": "uTvym2C3wndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Encoder"
      ],
      "metadata": {
        "id": "kmn52IN_wndP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedDistilBertModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedDistilBertModel, self).__init__()\n",
        "\n",
        "\n",
        "        self.backbone = AutoModel.from_pretrained(CFG.text_preset)\n",
        "        self.projection_head = ProjectionHead(384)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(**x).last_hidden_state.mean(dim=1)\n",
        "        x = self.projection_head(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def build_text_encoder():\n",
        "    model = ModifiedDistilBertModel()\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:34.007192Z",
          "iopub.execute_input": "2024-03-22T20:57:34.007591Z",
          "iopub.status.idle": "2024-03-22T20:57:34.016253Z",
          "shell.execute_reply.started": "2024-03-22T20:57:34.007551Z",
          "shell.execute_reply": "2024-03-22T20:57:34.015444Z"
        },
        "trusted": true,
        "id": "jIHtjhkzwndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SigLIP Model"
      ],
      "metadata": {
        "id": "IZzS6CEiwndP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ground_truth(batch_size=CFG.batch_size):\n",
        "    labels = -torch.ones((batch_size, batch_size))\n",
        "    labels += 2 * torch.eye(batch_size)\n",
        "    return labels\n",
        "\n",
        "class SigLIPLoss(nn.Module):\n",
        "    def __init__(self, name=\"siglip_loss\"):\n",
        "        super(SigLIPLoss, self).__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, y_true, y_pred):\n",
        "        loss = -torch.sum(F.logsigmoid(y_true * y_pred), dim=-1)\n",
        "        loss = torch.mean(loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SigLIPModule(LightningModule):\n",
        "    def __init__(self, image_encoder, text_encoder, tokenizer, logit_scale_init=2.30, logit_bias_init=-10.0):\n",
        "        super().__init__()\n",
        "        self.image_encoder = image_encoder\n",
        "        self.text_encoder = text_encoder\n",
        "        self.tokenizer = tokenizer\n",
        "        self.logit_scale = torch.nn.Parameter(torch.tensor(logit_scale_init))\n",
        "        self.logit_bias = torch.nn.Parameter(torch.tensor(logit_bias_init))\n",
        "        self.loss_fn = SigLIPLoss()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, images, encoded_texts):\n",
        "        image_features = self.image_encoder(images)\n",
        "        text_features = self.text_encoder(encoded_texts)\n",
        "        logits = image_features @ text_features.T\n",
        "        logits = self.logit_scale * logits + self.logit_bias\n",
        "        return logits\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, texts = batch\n",
        "        encoded_texts = self.tokenizer(texts, return_tensors='pt', padding=\"max_length\", max_length=200, truncation=True).to(self.device)\n",
        "        logits = self(images, encoded_texts)\n",
        "        ground_truth = get_ground_truth().to(self.device)\n",
        "        loss = self.loss_fn(ground_truth, logits)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=False, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, texts = batch\n",
        "        encoded_texts = self.tokenizer(texts, return_tensors='pt', padding=\"max_length\", max_length=200, truncation=True).to(self.device)\n",
        "        logits = self(images, encoded_texts)\n",
        "        ground_truth = get_ground_truth().to(self.device)\n",
        "        loss = self.loss_fn(ground_truth, logits)\n",
        "        self.log('val_loss', loss, on_step=True, on_epoch=False, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr=CFG.lr)\n",
        "        scheduler = {\n",
        "            'scheduler': CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.eta_min),\n",
        "            'interval': 'epoch',\n",
        "        }\n",
        "        return [optimizer], [scheduler]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:34.017516Z",
          "iopub.execute_input": "2024-03-22T20:57:34.017862Z",
          "iopub.status.idle": "2024-03-22T20:57:34.032707Z",
          "shell.execute_reply.started": "2024-03-22T20:57:34.017839Z",
          "shell.execute_reply": "2024-03-22T20:57:34.031923Z"
        },
        "trusted": true,
        "id": "9GAHcFPZwndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = ImageTextDataModule(train_paths, train_texts, valid_paths, valid_texts, batch_size=CFG.batch_size)\n",
        "wandb_logger = WandbLogger(project=\"SigLIP\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CFG.text_preset)\n",
        "\n",
        "image_encoder=build_image_encoder()\n",
        "text_encoder=build_text_encoder()\n",
        "model = SigLIPModule(image_encoder=image_encoder, text_encoder=text_encoder, tokenizer=tokenizer)\n",
        "model = model.to('cuda:0')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:34.035462Z",
          "iopub.execute_input": "2024-03-22T20:57:34.035813Z",
          "iopub.status.idle": "2024-03-22T20:57:35.783496Z",
          "shell.execute_reply.started": "2024-03-22T20:57:34.035788Z",
          "shell.execute_reply": "2024-03-22T20:57:35.782689Z"
        },
        "trusted": true,
        "id": "Y-Zr5ZEewndQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=\"checkpoints/\",\n",
        "    filename=\"{epoch}\",\n",
        "    save_top_k=-1,\n",
        "    every_n_epochs=1)\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=CFG.epochs,\n",
        "    logger=wandb_logger,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")\n",
        "\n",
        "trainer.fit(model, datamodule=data_module)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T20:57:35.784608Z",
          "iopub.execute_input": "2024-03-22T20:57:35.784902Z"
        },
        "trusted": true,
        "id": "pfNyimEywndQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(path):\n",
        "    img = Image.open(path)\n",
        "    img = data_module.transform(img)\n",
        "    img = img.unsqueeze(0).to('cuda:0')\n",
        "    return img\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
        "\n",
        "def process_text(text):\n",
        "    text = [f\"a photo of a {x}\" for x in text]\n",
        "    text = tokenizer(text, return_tensors='pt', padding=\"max_length\", max_length=200, truncation=True).to('cuda:0')\n",
        "    return text\n",
        "\n",
        "def zero_shot_classifier(image_path, labels):\n",
        "    image = process_image(image_path)\n",
        "    text = process_text(labels)\n",
        "    with torch.no_grad():\n",
        "        logits = model(image, text).cpu().numpy()\n",
        "\n",
        "    probabilities = softmax(logits)\n",
        "    pred_probabilities = dict(zip(labels, probabilities.squeeze()))\n",
        "    pred_probabilities = {k: round(v * 100, 2) for k, v in pred_probabilities.items()}\n",
        "    return pred_probabilities"
      ],
      "metadata": {
        "trusted": true,
        "id": "mSXZgVR0wndQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [i  for i in os.listdir('/kaggle/input/random-image-for-testing-classification') if i.endswith('.jpg')]\n",
        "classes = [i.replace('.jpg', '') for i in files]\n",
        "for epoch in range(CFG.epochs):\n",
        "    print(f'\\nEPOCH: {epoch}\\n')\n",
        "    model = SigLIPModule.load_from_checkpoint(f'checkpoints/epoch={epoch}.ckpt', image_encoder=image_encoder, text_encoder=text_encoder, tokenizer=tokenizer, logit_scale_init=2.30, logit_bias_init=-10.0).to('cuda:0').eval()\n",
        "    c = 0\n",
        "    for file in files:\n",
        "        ans = file.replace('.jpg', '')\n",
        "        out = zero_shot_classifier(os.path.join('/kaggle/input/random-image-for-testing-classification', file), classes)\n",
        "\n",
        "        top_prediction = max(out, key=out.get)\n",
        "        print(\"Top prediction:\", top_prediction, out[top_prediction])\n",
        "        if top_prediction == ans:\n",
        "            c += 1\n",
        "        print('GT pred:', ans, out[ans], '\\n')\n",
        "    print(f'Right preds {c}/{len(files)}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "mLAgqxZDwndQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJM5G1cVwndQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}